# Build Neural Network From Scratch

## Overview
This repository is my learning implementation of building a **neural network from scratch**, 
inspired by [Andrej Karpathy's tutorial](https://www.youtube.com/watch?v=VMj-3S1tku0).  

The project demonstrates:
- Forward and backward propagation
- Automatic differentiation concepts
- Training a neural network step by step

I have made **minor modifications** to suit my local environment (e.g., dataset path changes, Python version adjustments).  
This project is **strictly for learning purposes** and takes full inspiration from Andrej Karpathy's original work.

---

## References
- [YouTube Tutorial](https://www.youtube.com/watch?v=VMj-3S1tku0)  
- [micrograd (similar reference)](https://github.com/karpathy/micrograd)

---

## Usage
1. Clone the repository:
   git clone https://github.com/sabnam813/Neural-network-by-scratch.git
   cd neural-network-from-scratch

2. Open Jupyter Notebook:
jupyter notebook

3. Open and run the notebook:
micrograd_from_scratch.ipynb

# License
This project is inspired by Andrej Karpathy's tutorial,
licensed under the MIT License (see LICENSE).
My modifications are also released under the MIT License.